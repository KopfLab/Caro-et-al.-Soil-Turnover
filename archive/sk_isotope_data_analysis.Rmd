---
title: "Isotope data reduction"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: show
    df_print: paged
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include = FALSE}
# global knitting options for code rendering
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>")

# global knitting options for automatic saving of all plots as .png and .pdf
knitr::opts_chunk$set(
  dev = c("png", "pdf"),
  dev.args = list(pdf = list(encoding = "WinAnsi", useDingbats = FALSE)),
  fig.keep = "all",
  fig.path = file.path("fig_output", paste0(gsub("\\.[Rr]md", "", knitr::current_input()), "_"))
)
```

# Load packages

```{r, message=FALSE, warning=FALSE}
library(tidyverse) # general data wrangling and plotting
library(isoreader) # reading the raw data files
library(isoprocessor) # processing the data
library(isotopia) # devtools::install_github("isoverse/isotopia")
library(readxl)
source(file.path("scripts", "plotting_functions.R"))
```

This analysis was run using [isoreader](http://isoreader.kopflab.org) version `r packageVersion("isoreader")` and [isoprocessor](http://isoprocessor.kopflab.org/) version `r packageVersion("isoprocessor")`. 

All code chunks that contain a critical step towards the final data (i.e. do more than visualization or a data summary) are marked with `(*)` in the header to make it easier to follow all key steps during interactive use. 

# Load data

## Read raw data files (*)

```{r, warning=FALSE}
# set file path(s) to data files, folders or rds collections 
# can be multiple folders or mix of folders and files, using example data set here
# (this is a reduced data set of mostly standards with just a few example samples)
data_path <- file.path("data", "201911_isotope_data.cf.rds")

# read files
iso_files_raw <- 
  # path to data files
  data_path %>% 
  # read data files in parallel for fast read
  iso_read_continuous_flow() %>%
  # filter out files with read errors (e.g. from aborted analysis)
  iso_filter_files_with_problems()
```


## Process file info & peak table (*)

```{r}
# process file information
iso_files <- iso_files_raw %>% 
  # rename key file info columns
  iso_rename_file_info(analysis = Analysis, id1 = `Identifier 1`, id2 = `Identifier 2`) %>% 
  # parse text info into numbers
  iso_parse_file_info(number = analysis) %>% 
  # process other file information that is specific to the naming conventions
  # of this particular sequence
  iso_mutate_file_info(
    # what is the type of each analysis?
    type = case_when(
      str_detect(id2, "blank")        ~ "blank",
      str_detect(id1, "[Zz]ero")      ~ "on_off",
      str_detect(id1, "H3")           ~ "H3_factor",
      str_detect(id1, "F[89]")        ~ "std",
      TRUE                            ~ "sample"
    ),
    # what was the concentration? (assuming Preparation = concentration or volume)
    concentration = 
      ifelse(type == "std",  
             str_extract(Preparation, "[0-9.]+ ?ng( per |/)uL") %>% 
               parse_number() %>% iso_double_with_units("ng/uL"),
             NA),
    # what folder are the data files in? (assuming folder = sequence)
    folder = basename(dirname(file_path))
  ) %>% 
  # focus only on the relevant file info, discarding the rest
  iso_select_file_info(
    folder, analysis, file_datetime, id1, type, concentration, gc_method = `GC Method`
  ) %>% 
  # add in additional sample metadata (could be any info)
  # note: this would typically be stored in / read from a csv or excel file
  iso_add_file_info(
    readxl::read_excel(file.path("data", "isotopes_metadata.xlsx")),
    join_by = "id1"
  )

# set peak table from vendor data table with default isodat template
iso_files <- iso_set_peak_table_from_isodat_vendor_data_table(iso_files) %>% 
  # convert units from mV to V for amplitudes and area
  iso_convert_peak_table_units(V = mV, Vs = mVs)

# focus on sample files
sample_files <- iso_filter_files(iso_files, type == "sample" & analysis > 5651) %>% 
  iso_mutate_file_info(
    id1 = str_replace(id1, "^.*[mM]([^wWxX]+[wWxX]).*$", "m\\1") %>% 
      str_replace("6", "G") %>% str_replace("V", "N") %>% str_replace("X", "x") %>% str_replace("W", "w")
  )
```

## Standards chromatograms

Somehow the entire chromatograms shifted massively around for reasons that I don't understand at all - about a 900s shift.

```{r "standard_chromatograms", fig.width=8, fig.height=8}
# plot the chromatograms
iso_plot_continuous_flow_data(
  # all sample files
  iso_filter_files(iso_files, analysis %in% c(5645, 5695, 6212, 6225)),
  # select data and aesthetics
  data = c(2), color = folder, panel = analysis,
  linetype = gc_method,
  # zoom in on time interval
  time_interval = c(1050, 2100),
  # peak labels for all peaks > 2V
  peak_bounds = TRUE,
  peak_marker = TRUE,
  peak_label = iso_format(rt),
  #peak_label_size = 3,
  peak_label_filter = analysis == 5685 & amp2 > 1
) +
  theme(legend.position = "bottom", legend.direction = "vertical") +
  scale_x_continuous(breaks = (0:30) * 100)
#ggsave(file.path("fig_output", "chromatograms_standards.pdf"), width = 12, height = 10)
```


## Show file information

```{r}
# display file information
iso_files %>% 
  iso_get_file_info() %>% select(-file_id, -folder) %>% 
  iso_make_units_explicit() %>% knitr::kable()
```

## Example chromatograms


```{r "example_chromatograms", fig.width=8, fig.height=8}
# plot the chromatograms
iso_plot_continuous_flow_data(
  # all sample files
  iso_filter_files(sample_files, analysis < 6000 | id1 == "mAw"),
  # select data and aesthetics
  data = c(2), color = id1, panel = analysis,
  linetype = gc_method,
  # zoom in on time interval
  time_interval = c(1200, 1800),
  # peak labels for all peaks > 2V
  peak_bounds = TRUE,
  peak_marker = TRUE,
  peak_label = iso_format(rt),
  #peak_label_size = 3,
  peak_label_filter = analysis == 5685 & amp2 > 1
) +
  theme(legend.position = "bottom", legend.direction = "vertical")
#ggsave(file.path("fig_output", "chromatograms_example.pdf"), width = 12, height = 10)
```

# Peak Mapping

```{r}
# this information is often maintained in a csv or Excel file instead
# but generated here from scratch for demonstration purposes
peak_maps <- 
  readxl::read_excel(file.path("data","isotopes_peak_maps.xlsx"))
peak_maps %>% knitr::kable(digits = 0)

# identify peaks
sample_files_w_ids <- sample_files  %>% 
  # filter (focus on initial analytical run since later runs the GC was shit)
  iso_filter_files(analysis < 6000) %>% 
  # map peaks
  iso_map_peaks(peak_maps, map_id = type)
```

## Chromatograms

```{r "sample_chromatograms", fig.width=8, fig.height=8}
# plot the chromatograms
iso_plot_continuous_flow_data(
  # all sample files
  sample_files_w_ids,
  # select data and aesthetics
  data = c(2), color = id1, panel = analysis,
  # zoom in on time interval
  time_interval = c(1000, 3000),
  # peak labels for all peaks > 2V
  peak_bounds = TRUE,
  peak_marker = FALSE,
  peak_label = iso_format(compound, d2H),
  #peak_label_size = 3,
  peak_label_filter = compound != "unknown"
) 
```

# Process Data

## Equations

$$
\Delta F(t_2 - t_1) = \left(1 - e^{-\mu \cdot (t_2 - t_1)} \right) \left(a \cdot F_L - F (t_1)\right) 
$$


$$
\rightarrow \mu = -\frac{1}{t_2 - t_1} \ln{\left(\frac{a \cdot F_L - F(t_2)}{a \cdot F_L  - F(t_1)}\right)}
$$

## Calculations

### Enrichment data

```{r}
enrichment_data <-
  sample_files_w_ids %>% 
  # get peak table
  iso_get_peak_table(include_file_info = everything()) %>% 
  # focus on analyte compounds
  filter(compound != "H2") %>%
  # calculate relative amounts ignoring internal standard
  group_by(file_id) %>% 
  mutate(rel_amount = area2 / sum(area2[compound != "IS"])) %>% 
  ungroup() %>% 
  # diregard unknown compounds for now
  filter(compound != "unknown") %>% 
  # generate an easy to use sample label
  mutate(sample_label = sprintf("%.0fhrs%s%s", inc_time, ifelse(with_glu, " (with glu)", ""), ifelse(control, " - CTRL", ""))) %>% 
  # use the kill control as 0 time point (0 time point was not in the first analytical run and is useless in the 2nd)
  mutate(inc_time = ifelse(control == TRUE, 0, inc_time)) %>% 
  # test with just a few columns (expand here if more are needed)
  select(sample_label, compound, rt, id1, inc_time, with_glu, rel_amount, d2H) %>% 
  # convert dD to fractional abundance
  mutate(
    F2H.ppm = 
      delta(d2H, ref_ratio = get_standard("2H")) %>% 
      to_ratio() %>% to_abundance() %>% 
      as.numeric %>% { .*1e6 }
  )
```

### Labeling times

```{r}
FL.ppm = 0.5/100 * 1e6 # tracer strength = 0.5%
a = 0.5 # incorporation efficiency of 50%

# calculates all permutations of enrichment calculations
labeling_rates <- 
  full_join(
    enrichment_data,
    select(enrichment_data, compound, with_glu, start_inc_time = inc_time, 
           start_d2H = d2H, start_F2H.ppm = F2H.ppm),
    by = c("compound", "with_glu")
  ) %>% 
  filter(inc_time > start_inc_time | start_inc_time == 0) %>% 
  # calculate differences
  mutate(
    inc_time_label = sprintf("%.0f to %.0f hrs", start_inc_time, inc_time),
    Dd2H = d2H - start_d2H,
    DF2H.ppm = F2H.ppm - start_F2H.ppm
  ) %>% 
  select(-start_d2H) %>% 
  arrange(with_glu, compound, inc_time, start_inc_time) %>% 
  # calculate labeling time
  mutate(
    mu.1_hr = case_when(
      inc_time - start_inc_time == 0 ~ NA_real_,
      TRUE ~ - (1/(inc_time - start_inc_time))*(log((a*FL.ppm - F2H.ppm)/(a*FL.ppm - start_F2H.ppm)))
    ),
    mu.1_d = mu.1_hr * 24,
    gen.d = log(2) / (mu.1_d)
  )

labeling_rates
```


# Analyze Data

## Delta data overview

```{r "data_overview_figure_permil", fig.width=12, fig.height=10}
# all data in delta space
labeling_rates %>% 
  filter(start_inc_time == 0) %>% 
  gather("var", "val", d2H, Dd2H) %>% 
  iso_plot_data(
    x = inc_time, y = val, color = compound, shape = with_glu, size = rel_amount,
    points = TRUE,
    lines = TRUE,
    panel = with_glu ~ var
    #panel_scales = "fixed"
  )
```

## Abundace [ppm]

```{r "data_overview_figure_ppm", fig.width=12, fig.height=10}
# all data in abundace space
labeling_rates %>% 
  filter(start_inc_time == 0) %>% 
  gather("var", "val", DF2H.ppm) %>% 
  iso_plot_data(
    x = inc_time, y = val, color = compound, shape = with_glu, size = rel_amount,
    points = TRUE,
    lines = TRUE,
    panel = with_glu ~ var
  )
```

## Generation times / Growth rates

```{r "all_generation_times"}
labeling_rates %>% 
  mutate(glu = ifelse(with_glu, "+glucose", "no glucose")) %>% 
  filter(gen.d > 0) %>% 
  filter(inc_time_label %in% c("0 to 1 hrs", "1 to 6 hrs", "0 to 6 hrs", "6 to 50 hrs")) %>% 
  ggplot() +
  aes(compound, mu.1_d, fill = inc_time_label) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_figure(axis_x_rotate = 90) +
  facet_wrap(~glu, scales = "free_y", ncol = 1)
```

# Time course

```{r}
make_time_course_plot <- function(df) {
  
  # calculate weighted mean of multiple lipids
  calculate_DF2H_weighted_mean <- function(df) {
    df %>% 
      group_by(inc_time, inc_time_label) %>% 
      summarize(
        DF2H.ppm = sum(DF2H.ppm * rel_amount) / sum(rel_amount),
        name = "weighted\nmean"
      )
  }
  
  quant_limit <- tibble(
    inc_time = 5, DF2H.ppm = c(0.8 * max(df$DF2H.ppm), 0.8 * max(df$DF2H.ppm) + 15), 
    name = as.character(expression(atop(Delta*D==15*'ppm',Delta*delta*D%~~%100*'‰')))
  )
  
  df %>% 
    dplyr::filter(start_inc_time == 0) %>%
    ggplot() +
    aes(x = inc_time, y = DF2H.ppm, label = name, group = name) + #, color = name) +
    #geom_smooth(method = "lm", formula = y ~ x + 0, se = FALSE) +
    geom_line(size = 0.5, color = "gray") +
    geom_line(data = calculate_DF2H_weighted_mean, size = 1.5, color = "black") +
    geom_point(mapping = aes(size = rel_amount), color = "gray") +
    geom_point(data = calculate_DF2H_weighted_mean, size = 6, shape = 25, color = "black", fill = "black") +
    ggrepel::geom_label_repel(
      data = function(df) {
        df <- filter(df, inc_time == 50)
        vctrs::vec_rbind(df, calculate_DF2H_weighted_mean(df))
      },
      min.segment.length = 0, seed = 7,
      nudge_x = 5, force = 3
    ) +
    geom_line(data = quant_limit, size = 2) +
    ggrepel::geom_label_repel(
      data = filter(quant_limit, DF2H.ppm == max(DF2H.ppm)),
      min.segment.length = 0, seed = 7,
      nudge_x = 10, nudge_y = 10,
      parse = TRUE
    ) +
    #facet_wrap(~compound, scales = "free_y") + 
    theme_figure(legend = FALSE) +
    scale_x_continuous(breaks = c(0:6) * 10) +
    expand_limits(x = 60) +
    labs(x = "incubation time [hrs]", y = expression(Delta*D~"[ppm]"))
  
}
```


## No glucose time course

```{r "time_course_no_glucose", warning=FALSE}
peaks_of_interest <- readxl::read_excel(file.path("data", "peaks_of_interest.xlsx"))

noglu_enrichment_data <- 
  labeling_rates %>% 
  right_join(peaks_of_interest, by = c("compound" = "mapping_name")) %>% 
  # include 1 hour time point? yes, important part of the trend
  #filter(inc_time != 1) %>% 
  filter(!with_glu) 

p_noglu_time_course <- make_time_course_plot(noglu_enrichment_data)
p_noglu_time_course
```


## Glucose time course

```{r "time_course_glucose", fig.width=8, fig.height=6, warning=FALSE}
peaks_of_interest <- readxl::read_excel(file.path("data", "peaks_of_interest.xlsx"))

glu_enrichment_data <- 
  labeling_rates %>% 
  right_join(peaks_of_interest, by = c("compound" = "mapping_name")) %>% 
  # include 1 hr tp? --> makes it more confusing than one might think
  filter(inc_time != 1) %>% 
  filter(with_glu)

p_glu_time_course <- make_time_course_plot(glu_enrichment_data)
p_glu_time_course
```

# Growth rates

```{r}
make_growth_rate_plot <- function(df, mu_breaks, ylim, tps = c("0 to 6 hrs", "6 to 50 hrs")) {
  
  calculate_mu_weighted_mean <- function(df) {
    df %>% 
      summarize(
        mu.1_d = sum(mu.1_d * rel_amount) / sum(rel_amount),
        mu_min.1_d = sum(mu_min.1_d * rel_amount) / sum(rel_amount),
        mu_max.1_d = sum(mu_max.1_d * rel_amount) / sum(rel_amount),
        name = "weighted\nmean"
      )
  }
  
  df %>% 
    filter(gen.d > 0) %>% 
    filter(inc_time_label %in% tps) %>% 
    group_by(name) %>% 
    filter(length(mu.1_d) == length(tps)) %>% 
    summarize(
      n_estimates = n(),
      # these end up being very assymetric activities
      mu_min.1_d = min(mu.1_d),
      mu_max.1_d = max(mu.1_d),
      # weighted mean (by time interval length)
      mu.1_d = sum((inc_time - start_inc_time) * mu.1_d) / sum(inc_time - start_inc_time),
      rel_amount = mean(rel_amount)
    ) %>% 
    { bind_rows(., calculate_mu_weighted_mean(.)) } %>% 
    # sort by abundance
    arrange(mu.1_d) %>% 
    mutate(name = factor(name) %>% fct_inorder()) %>% 
    ggplot() +
    aes(name, mu.1_d) +
    geom_bar(data = function(df) filter(df, name != "weighted\nmean"), stat = "identity", fill = "gray") +
    geom_bar(data = function(df) filter(df, name == "weighted\nmean"), stat = "identity", fill = "gray30") +
    # geom_errorbar(
    #   data = function(df) filter(df, !is.na(mu_min.1_d)),
    #   mapping = aes(ymin = mu_min.1_d, ymax = mu_max.1_d),
    #   width = 0
    # ) +
    scale_x_discrete(drop=FALSE) +
    scale_y_continuous(
      breaks = mu_breaks,
      labels = function(x) {
        days <- round(log(2)/x)
        days <- ifelse(days > 30, paste(round(days/30, 1), "months"), paste(round(days), "days"))
        paste0(x, "/day\n~", days)
      },
      expand = c(0, 0)
    ) +
    expand_limits(y = ylim) +
    theme_figure(axis_x_rotate = 90) +
    theme() +
    labs(x = NULL, y = "apparent growth rate / generation time") +
    coord_flip()
}
```

## No glucose growth rates

```{r "growth_rates)noglucose", fig.width=8, fig.height=6, warning=FALSE}
p_noglu_rates <- make_growth_rate_plot(noglu_enrichment_data, ylim = 0.018, mu_breaks = c(0.001, 0.005, 0.01, 0.015))
p_noglu_rates
```

## Glucose growth rates

```{r "growth_rates_glucose", fig.width=8, fig.height=6, warning=FALSE}
p_glu_rates <- make_growth_rate_plot(glu_enrichment_data, ylim = 0.085, mu_breaks = c(0.0023, 0.015, 0.031, 0.05, 0.071))
p_glu_rates
```

# Combined plot

## No glucose

```{r "labeling_plot_noglu", fig.width=12, fig.height=7, warning=FALSE}
library(cowplot)
plot_grid(
  p_noglu_time_course,
  p_noglu_rates,
  labels = "AUTO", 
  rel_widths = c(1, 1),
  align = "h"
)
```

## Glucose

```{r "labeling_plot_glu", fig.width=12, fig.height=7, warning=FALSE}
library(cowplot)
plot_grid(
  p_glu_time_course,
  p_glu_rates,
  labels = "AUTO", 
  rel_widths = c(1, 1),
  align = "h"
)
```

# Abundances

```{r "peak_abundances"}
# what do the abundances look like?
# NOTE: make sure that peak intregrations are all correct, they migt be off by quite a bit
vctrs::vec_rbind(
  glu_enrichment_data,
  noglu_enrichment_data,
) %>% 
  arrange(inc_time) %>% 
  mutate(
    x = paste(inc_time, "hrs") %>% factor() %>% fct_inorder(),
    glu = ifelse(with_glu, "+glucose", "no glucose")
  ) %>% 
  group_by(with_glu, inc_time) %>% 
  mutate(rel_amount = rel_amount / sum(rel_amount)) %>% 
  ggplot()+
  aes(paste(inc_time, "hrs"), rel_amount, fill = name) +
  geom_bar(stat = "identity") +
  labs(x = "sample") +
  facet_wrap(~glu)
```


# ===== OLD CODE =====

# all growth data

```{r, eval=FALSE}
calc_data %>% 
  filter(
    !is.na(u.1_hr), 
    u.1_hr > 0
  ) %>% 
  mutate(
    `var µ [1/day]` = u.1_d,
    `var T [days]` = gen.d,
    `var Amt [%]` = 100 * rel_amount_present
  ) %>% 
  gather(key = "variable", value = "value", starts_with("var")) %>% 
  mutate(variable = str_remove(variable, "^var ") %>% factor() %>% fct_inorder()) %>% 
  ggplot() +
    aes(compound, y = value, fill = factor(inc_time)) +
    geom_bar(stat = "identity", position = "dodge") +
    facet_grid(variable ~ panel, scales = "free_y", switch = "y") +
    labs(x = NULL, y = NULL) + 
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
#  coord_cartesian(y = c(0, 1000))
```

```{r, eval=FALSE}
calc_data %>% 
  filter(
    !is.na(u.1_hr), 
    u.1_hr > 0
  ) %>% 
  mutate(
    `var µ [1/day]` = u.1_d
  ) %>% 
  gather(key = "variable", value = "value", starts_with("var")) %>% 
  mutate(variable = str_remove(variable, "^var ") %>% factor() %>% fct_inorder()) %>% 
  ggplot() +
  aes(compound, y = value, fill = factor(inc_time)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(variable ~ panel, scales = "free_y", switch = "y") +
  labs(x = NULL, y = NULL) + 
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
#  coord_cartesian(y = c(0, 1000))
```


# weighted growth data

```{r, eval=FALSE}
spread_data <- calc_data %>% 
  filter(!control) %>%  
  {
    full_join(
      filter(., with_glu) %>% select(inc_time, compound, with_glu_rel_amount = rel_amount_present, with_glu_u.1_mon = u.1_mon),
      filter(., !with_glu) %>% select(inc_time, compound, no_glu_rel_amount = rel_amount_present, no_glu_u.1_mon = u.1_mon),
      by = c("inc_time", "compound")
    ) %>% 
      mutate(mean_rel_amount = 0.5 * with_glu_rel_amount + 0.5 * no_glu_rel_amount)
  }
spread_data_sum <- spread_data %>% 
  group_by(inc_time) %>% 
  summarise(
    with_glu_u.1_mon = sum(with_glu_rel_amount * with_glu_u.1_mon) / sum(with_glu_rel_amount),
    no_glu_u.1_mon = sum(no_glu_rel_amount * no_glu_u.1_mon) / sum(no_glu_rel_amount),
    mean_rel_amount = 1
    # what is a good weighted measure of the mu distribution spread??
  ) 
spread_data_sum
```


```{r, eval=FALSE}
ggplot() +
  aes(no_glu_u.1_mon, with_glu_u.1_mon, shape = paste(inc_time, "hours")) +
  geom_abline(slope = 1, intercept = 0, color = 'orange') +
  xlab('Cell Turnover per Month: No Glucose') +
  ylab('Cell Turnover per Month: With Glucose') +
  # individual compounds
  #geom_path(data = spread_data, mapping = aes(color = compound, shape = NULL), alpha = 0.5) +
  #geom_point(data = spread_data, mapping = aes(color = compound, size = 100 * mean_rel_amount), alpha = 0.5) +
  # weighted means
  geom_path(data = spread_data_sum, mapping = aes(shape = NULL)) +
  geom_point(data = spread_data_sum, mapping = aes(size = 100 * mean_rel_amount)) +
  #coord_fixed(x = c(0, 15), y = c(0, 15))
  coord_fixed(x = c(0, 4), y = c(0, 4))
  
```


```{r, eval=FALSE}

mean_u <- read_csv(file.path("data", "weighted_mean_u.csv"))
mean_u %>%
ggplot() +
  aes(x = factor(inc_time), y = u.1_mon, fill = with_glu) +
  geom_bar(stat = 'identity', position = 'dodge') +
  theme_bw() +
  xlab('Incuation Time') +
  ylab('Generations per Month')
ggsave(file.path("figures", "weighted_mean_u_bar.png"), width = 8, height = 8)
```


# control - look good

```{r, eval=FALSE}
calc_data %>% 
  filter(control) %>% 
  ggplot() +
  aes(compound, d2H, color = panel) +
  geom_point() +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```



# FOR PROCESSING ONLY

# Export data

```{r, eval=FALSE}
irms_example_data <- 
  sample_files_w_ids %>%
  iso_filter_files(analysis == 5689) %>% 
  iso_get_peak_table() %>% 
  filter(compound != "H2") %>% 
  select(rt, rt_start, rt_end, amp2, area2) %>% 
  mutate(rel_height = amp2/sum(amp2) * 100) %>% 
  filter(rel_height > 1) 

irms_example_data %>% 
  openxlsx::write.xlsx(file.path("tables", "gc_irms_single_sample_peak_table.xlsx"))
```

# Peak Mapping help

```{r, eval=FALSE}
tsq_example_data <- read_excel(file.path("tables", "tsq_single_sample_peak_table.xlsx"))
```


```{r, eval=FALSE}
bind_rows(
  irms_example_data %>% mutate(type = "irms") %>% iso_strip_units(),
  tsq_example_data %>% mutate(type = "tsq")
) %>% 
  ggplot() +
  aes(rt, rel_height, label = paste0(`Peak Name`, "\n", round(rt))) +
  geom_bar(stat = "identity")+
  ggrepel::geom_text_repel(color = "red", alpha = 0.5, min.segment.length = 0)+
  facet_grid(type ~ .)
ggsave(file.path("figures", "irms_tsq_comparison2.pdf"), width = 12, height = 8)
```


