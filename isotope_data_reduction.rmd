---
title: "Isotope data reduction"
date: "`r Sys.Date()`"
  html_document:
    code_folding: show
    df_print: paged
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include = FALSE}
# global knitting options for code rendering
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>")

# global knitting options for automatic saving of all plots as .png and .pdf
knitr::opts_chunk$set(
  dev = c("png", "pdf"),
  dev.args = list(pdf = list(encoding = "WinAnsi", useDingbats = FALSE)),
  fig.keep = "all",
  fig.path = file.path("fig_output", paste0(gsub("\\.[Rr]md", "", knitr::current_input()), "_"))
)
```

# Load packages

```{r, message=FALSE, warning=FALSE}
library(tidyverse) # general data wrangling and plotting
library(isoreader) # reading the raw data files
library(isoprocessor) # processing the data
library(isotopia)
library(readxl)
```

This analysis was run using [isoreader](http://isoreader.kopflab.org) version `r packageVersion("isoreader")` and [isoprocessor](http://isoprocessor.kopflab.org/) version `r packageVersion("isoprocessor")`. 

All code chunks that contain a critical step towards the final data (i.e. do more than visualization or a data summary) are marked with `(*)` in the header to make it easier to follow all key steps during interactive use. 

# Load data

## Read raw data files (*)

```{r, warning=FALSE}
# set file path(s) to data files, folders or rds collections 
# can be multiple folders or mix of folders and files, using example data set here
# (this is a reduced data set of mostly standards with just a few example samples)
data_path <- file.path("data", "201911_isotope_data.cf.rds")

# read files
iso_files_raw <- 
  # path to data files
  data_path %>% 
  # read data files in parallel for fast read
  iso_read_continuous_flow() %>%
  # filter out files with read errors (e.g. from aborted analysis)
  iso_filter_files_with_problems()
```


## Process file info & peak table (*)

```{r}
# process file information
iso_files <- iso_files_raw %>% 
  # rename key file info columns
  iso_rename_file_info(analysis = Analysis, id1 = `Identifier 1`, id2 = `Identifier 2`) %>% 
  # parse text info into numbers
  iso_parse_file_info(number = analysis) %>% 
  # process other file information that is specific to the naming conventions
  # of this particular sequence
  iso_mutate_file_info(
    # what is the type of each analysis?
    type = case_when(
      str_detect(id1, "[Zz]ero")      ~ "on_off",
      str_detect(id1, "H3")           ~ "H3_factor",
      str_detect(id1, "F8")           ~ "std",
      TRUE                            ~ "sample"
    ),
    # what was the concentration? (assuming Preparation = concentration or volume)
    concentration = 
      ifelse(type == "std",  
             str_extract(Preparation, "[0-9.]+ ?ng( per |/)uL") %>% 
               parse_number() %>% iso_double_with_units("ng/uL"),
             NA),
    # what folder are the data files in? (assuming folder = sequence)
    folder = basename(dirname(file_path))
  ) %>% 
  # focus only on the relevant file info, discarding the rest
  iso_select_file_info(
    folder, analysis, file_datetime, id1, type, concentration
  ) %>% 
  # add in additional sample metadata (could be any info)
  # note: this would typically be stored in / read from a csv or excel file
  iso_add_file_info(
    readxl::read_excel(file.path("data", "isotopes_metadata.xlsx")),
    join_by = "id1"
  )

# set peak table from vendor data table with default isodat template
iso_files <- iso_set_peak_table_from_isodat_vendor_data_table(iso_files) %>% 
  # convert units from mV to V for amplitudes and area
  iso_convert_peak_table_units(V = mV, Vs = mVs)

# focus on sample files
sample_files <- iso_filter_files(iso_files, type == "sample" & analysis > 5651)
```


## Show file information

```{r}
# display file information
iso_files %>% 
  iso_get_file_info() %>% select(-file_id, -folder) %>% 
  iso_make_units_explicit() %>% knitr::kable()
```

## Example chromatograms

```{r "example_chromatograms", fig.width=8, fig.height=8}
# plot the chromatograms
iso_plot_continuous_flow_data(
  # all sample files
  sample_files,
  # select data and aesthetics
  data = c(2), color = id1, panel = analysis,
  # zoom in on time interval
  time_interval = c(1000, 3000),
  # peak labels for all peaks > 2V
  peak_bounds = TRUE,
  peak_marker = FALSE,
  peak_label = iso_format(rt),
  #peak_label_size = 3,
  peak_label_filter = analysis == 5685 & amp2 > 1
) 
```

# Peak Mapping

```{r}
# this information is often maintained in a csv or Excel file instead
# but generated here from scratch for demonstration purposes
peak_maps <- 
  readxl::read_excel(file.path("data","isotopes_peak_maps.xlsx"))
peak_maps %>% knitr::kable(digits = 0)

# identify peaks
sample_files_w_ids <- sample_files  %>% 
  # map peaks
  iso_map_peaks(peak_maps, map_id = type)
```

## Chromatograms

```{r "sample_chromatograms", fig.width=8, fig.height=8}
# plot the chromatograms
iso_plot_continuous_flow_data(
  # all sample files
  sample_files_w_ids,
  # select data and aesthetics
  data = c(2), color = id1, panel = analysis,
  # zoom in on time interval
  time_interval = c(1000, 3000),
  # peak labels for all peaks > 2V
  peak_bounds = TRUE,
  peak_marker = FALSE,
  peak_label = iso_format(compound, d2H),
  #peak_label_size = 3,
  peak_label_filter = compound != "unknown"
) 
```

## Data *

```{r}
real_data <- 
  sample_files_w_ids %>% 
  iso_get_peak_table(include_file_info = everything()) %>% 
  filter(compound != "H2") %>% 
  group_by(file_id) %>% 
  mutate(rel_amount = area2 / sum(area2[compound != "IS"])) %>% 
  ungroup() %>% 
  filter(compound != "unknown") 
```


```{r}
# Unaltered data plot
real_data %>% 
  mutate(sample_label = iso_format(control, inc_time, with_glu)) %>% 
  mutate(inc_time = ifelse(control == TRUE, 0, inc_time)) %>% 
  iso_plot_data(
    x = inc_time, y = d2H, color = compound, shape = with_glu, size = rel_amount,
    points = TRUE,
    lines = TRUE,
    panel = with_glu ~ .
    #panel_scales = "fixed"
  ) +
  geom_hline(yintercept = -200) +
  geom_hline(yintercept = -180)
ggsave(file.path("figures", "d2H_all_compounds_2.pdf"), width = 12, height = 8)


```

```{r}
real_data_normalized <- real_data
real_data_normalized <- real_data_normalized %>%
  mutate(sample_label = iso_format(control, inc_time, with_glu)) %>%
  select(id1, control, inc_time, with_glu, compound, d2H, rel_amount)

real_data_normalized2 <- read_csv(file.path("data", "real_data_normalized.csv"))

real_data_normalized2 %>% filter(control != TRUE) %>%
  iso_plot_data(
    x = inc_time, y = d2H_normal, color = compound, shape = with_glu,
    points = TRUE,
    lines = TRUE,
    panel = with_glu ~ .,
    panel_scales = "fixed") #+ geom_smooth(method = "lm", alpha = .15, aes(fill = with_glu))
ggsave(file.path("figures", "d2H_comp_normalized_zoomed.png"), width = 12, height = 8)
```

```{r}
# Mean Across Compounds
real_data_abbreviated <- real_data
real_data_abbreviated <- real_data_abbreviated %>%
  mutate(sample_label = iso_format(control, inc_time, with_glu)) %>%
  select(id1, control, inc_time, with_glu, compound, d2H, rel_amount)

real_data_abbreviated <- real_data_abbreviated %>%
  group_by(inc_time, with_glu) %>%
  summarise(mean_d2H = mean(d2H),
            sdev = sd(d2H))



real_data_abbreviated %>%
  iso_plot_data(
    x = inc_time, y = mean_d2H, color = with_glu, shape = with_glu,
    points = TRUE,
    lines = TRUE
    #panel = with_glu ~ .
    #panel_scales = "fixed"
  ) + geom_smooth(method = "lm", alpha = .15, aes(fill = with_glu))
ggsave(file.path("figures", "d2H_averaged_comp.pdf"), width = 12, height = 8)
```


## Labeling Calculations
For example:
FL = 0.005 # tracer strength = 0.5%
a = 0.5 # incorporation efficiency of 50%
FT = 0.02 # resultant isotopic enrichment
F0 = 0.0124 # beginning isotopic enrichment

```{r}

gencalc <- function(a, FT, F0, FL, t) {
  case_when(
    t == 0 ~ NA_real_,
    TRUE ~ - (1/t)*(log((FT - a*FL)/(F0 - a*FL)))
  )
}

'
FL = 0.005 # tracer strength = 0.5% --> 
a = 0.5 # incorporation efficiency of 50%
FT = 0.02 # resultant isotopic enrichment
F0 = 0.0124 # beginning isotopic enrichment
'

calc_data <- real_data_normalized2
ref_ratio <- get_standard("2H") %>% as.numeric()
# Calculate the starting iso enrichment NOTE: using 1hr as a standin for 0hr until that data is acquired

calc_data <- calc_data %>%
  # only focus on fatty acids
  filter(!compound %in% c("alkane", "C23:0 (IS)")) %>% 
  mutate(
    R = (d2H/1000 +1) * ref_ratio,
    t = inc_time,
    FT = R / (1 + R)
  ) %>% 
  # for each compound in each time series
  group_by(with_glu, compound) %>%
  mutate(
    # use negative controls as reference
    t0 = 0,
    n_t0 = sum(control),
    F0 = mean(FT[control]),
    t = ifelse(control, 0, t)
    # use first time point as reference
    #t0 = min(t),
    #n_t0 = sum(t == t0),
    #F0 = mean(FT[t == t0])
  ) %>% 
  ungroup() %>% 
  #mutate(u = NA) %>%
  # calculate growth rate mu
  mutate(
    d_FT = FT - F0,
    d_t = t - t0,
    u.1_hr = gencalc(a = a, FT = d_FT, F0 = 0, FL = fl, t = d_t),
    u.1_d = u.1_hr * 24,
    u.1_mon = u.1_d * 30,
    gen.d = log(2) / u.1_d
  ) %>% 
  # calculate relative amounts for shared peaks
  group_by(control, with_glu, inc_time) %>% 
  mutate(rel_amount_present = rel_amount / sum(rel_amount)) %>% 
  ungroup() %>% 
  # general info
  mutate(
    panel = ifelse(with_glu, "with glucose", "no glucose"),
    compound = factor(compound) %>% fct_inorder()
  ) %>% 
  identity()





```

# all growth data

```{r}
calc_data %>% 
  filter(
    !is.na(u.1_hr), 
    u.1_hr > 0
  ) %>% 
  mutate(
    `var µ [1/day]` = u.1_d,
    `var T [days]` = gen.d,
    `var Amt [%]` = 100 * rel_amount_present
  ) %>% 
  gather(key = "variable", value = "value", starts_with("var")) %>% 
  mutate(variable = str_remove(variable, "^var ") %>% factor() %>% fct_inorder()) %>% 
  ggplot() +
    aes(compound, y = value, fill = factor(inc_time)) +
    geom_bar(stat = "identity", position = "dodge") +
    facet_grid(variable ~ panel, scales = "free_y", switch = "y") +
    labs(x = NULL, y = NULL) + 
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
#  coord_cartesian(y = c(0, 1000))
```

```{r}
calc_data %>% 
  filter(
    !is.na(u.1_hr), 
    u.1_hr > 0
  ) %>% 
  mutate(
    `var µ [1/day]` = u.1_d
  ) %>% 
  gather(key = "variable", value = "value", starts_with("var")) %>% 
  mutate(variable = str_remove(variable, "^var ") %>% factor() %>% fct_inorder()) %>% 
  ggplot() +
  aes(compound, y = value, fill = factor(inc_time)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_grid(variable ~ panel, scales = "free_y", switch = "y") +
  labs(x = NULL, y = NULL) + 
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
#  coord_cartesian(y = c(0, 1000))
```


# weighted growth data

```{r}
spread_data <- calc_data %>% 
  filter(!control) %>%  
  {
    full_join(
      filter(., with_glu) %>% select(inc_time, compound, with_glu_rel_amount = rel_amount_present, with_glu_u.1_mon = u.1_mon),
      filter(., !with_glu) %>% select(inc_time, compound, no_glu_rel_amount = rel_amount_present, no_glu_u.1_mon = u.1_mon),
      by = c("inc_time", "compound")
    ) %>% 
      mutate(mean_rel_amount = 0.5 * with_glu_rel_amount + 0.5 * no_glu_rel_amount)
  }
spread_data_sum <- spread_data %>% 
  group_by(inc_time) %>% 
  summarise(
    with_glu_u.1_mon = sum(with_glu_rel_amount * with_glu_u.1_mon) / sum(with_glu_rel_amount),
    no_glu_u.1_mon = sum(no_glu_rel_amount * no_glu_u.1_mon) / sum(no_glu_rel_amount),
    mean_rel_amount = 1
    # what is a good weighted measure of the mu distribution spread??
  ) 
spread_data_sum
```


```{r}
ggplot() +
  aes(no_glu_u.1_mon, with_glu_u.1_mon, shape = paste(inc_time, "hours")) +
  geom_abline(slope = 1, intercept = 0, color = 'orange') +
  xlab('Cell Turnover per Month: No Glucose') +
  ylab('Cell Turnover per Month: With Glucose') +
  # individual compounds
  #geom_path(data = spread_data, mapping = aes(color = compound, shape = NULL), alpha = 0.5) +
  #geom_point(data = spread_data, mapping = aes(color = compound, size = 100 * mean_rel_amount), alpha = 0.5) +
  # weighted means
  geom_path(data = spread_data_sum, mapping = aes(shape = NULL)) +
  geom_point(data = spread_data_sum, mapping = aes(size = 100 * mean_rel_amount)) +
  #coord_fixed(x = c(0, 15), y = c(0, 15))
  coord_fixed(x = c(0, 4), y = c(0, 4))
  
```


```{r}

mean_u <- read_csv(file.path("data", "weighted_mean_u.csv"))
mean_u %>%
ggplot() +
  aes(x = factor(inc_time), y = u.1_mon, fill = with_glu) +
  geom_bar(stat = 'identity', position = 'dodge') +
  theme_bw() +
  xlab('Incuation Time') +
  ylab('Generations per Month')
ggsave(file.path("figures", "weighted_mean_u_bar.png"), width = 8, height = 8)
```


# control - look good

```{r}
calc_data %>% 
  filter(control) %>% 
  ggplot() +
  aes(compound, d2H, color = panel) +
  geom_point() +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```



# FOR PROCESSING ONLY

# Export data

```{r}
irms_example_data <- 
  sample_files_w_ids %>%
  iso_filter_files(analysis == 5689) %>% 
  iso_get_peak_table() %>% 
  filter(compound != "H2") %>% 
  select(rt, rt_start, rt_end, amp2, area2) %>% 
  mutate(rel_height = amp2/sum(amp2) * 100) %>% 
  filter(rel_height > 1) 

irms_example_data %>% 
  openxlsx::write.xlsx(file.path("tables", "gc_irms_single_sample_peak_table.xlsx"))
```

# Peak Mapping help

```{r}
tsq_example_data <- read_excel(file.path("tables", "tsq_single_sample_peak_table.xlsx"))
```


```{r}
bind_rows(
  irms_example_data %>% mutate(type = "irms") %>% iso_strip_units(),
  tsq_example_data %>% mutate(type = "tsq")
) %>% 
  ggplot() +
  aes(rt, rel_height, label = paste0(`Peak Name`, "\n", round(rt))) +
  geom_bar(stat = "identity")+
  ggrepel::geom_text_repel(color = "red", alpha = 0.5, min.segment.length = 0)+
  facet_grid(type ~ .)
ggsave(file.path("figures", "irms_tsq_comparison2.pdf"), width = 12, height = 8)
```


